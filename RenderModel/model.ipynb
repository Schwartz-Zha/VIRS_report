{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PlayGround2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ChV0L5d03idd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import pickle\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "import math\n",
        "import numbers\n",
        "from torch.utils import data\n",
        "from skimage import io\n",
        "#3D plot\n",
        "from matplotlib import cm\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pvpEDj103phP"
      },
      "outputs": [],
      "source": [
        "#put tensor onto GPU\n",
        "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6yvyJuhv3t8N"
      },
      "outputs": [],
      "source": [
        "class Plane:\n",
        "    def __init__(self, o, e, e1, e2, l, w, n):\n",
        "        \"\"\"\n",
        "        o: pinhole \n",
        "        e: start from pinhole camera o and ends at the centter of Sensor Board\n",
        "        e1,e2: axis of the board\n",
        "        l,w: length and width of the board\n",
        "        n: sample density of all the points in unit length\n",
        "        \"\"\"\n",
        "        \n",
        "        self.o = o\n",
        "        self.e = e\n",
        "        self.e1 = e1\n",
        "        self.e2 = e2\n",
        "        self.l = l\n",
        "        self.w = w\n",
        "        self.n = n\n",
        "        self.sample_num = [self.l * self.n, self.w * self.n]\n",
        "        \n",
        "    def get_n(self):\n",
        "        \"\"\"return sample x, y and the vector from o to each sample point on the plane\"\"\"\n",
        "        \n",
        "        ori = torch.empty(self.l * self.n, self.w * self.n, 3)\n",
        "\n",
        "        for i in range(0, self.l * self.n):\n",
        "            for j in range(0, self.w * self.n):\n",
        "                ori[i, j] = self.e + (i / (self.l * self.n) - 0.5)* self.e1 * self.l + (j / (self.w * self.n) - 0.5)* self.e2 * self.w\n",
        "                \n",
        "        return ori\n",
        "         "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ghrUfWxP3zqN"
      },
      "outputs": [],
      "source": [
        "class Gaussian: \n",
        "    \n",
        "    def __init__(self, c, mu, sigma, albedo):\n",
        "        '''\n",
        "        c: (N, g)\n",
        "        mu: (N, g, 3)\n",
        "        sigma: (N, g)\n",
        "        albedo: (N, g, C)\n",
        "        N: batch size; g: number of gaussians; C: channel\n",
        "        '''\n",
        "        self.c = c\n",
        "        self.mu = mu\n",
        "        self.sigma = sigma\n",
        "        self.albedo = albedo\n",
        "        \n",
        "    def get_c(self):\n",
        "#       return torch.sigmoid(self.c) * MAX_C\n",
        "         return self.c\n",
        "    \n",
        "    def get_sigma(self):\n",
        "#        return torch.sigmoid(self.sigma) * MAX_SIGMA\n",
        "         return self.sigma\n",
        "        \n",
        "    def density(self, x):\n",
        "        '''\n",
        "        x: (N, g, H, W, 3)\n",
        "        return: (N, g, H, W)\n",
        "        H:height of picture; W: width of picture\n",
        "        '''\n",
        "        H = x.size()[2]\n",
        "        W = x.size()[3]\n",
        "        \n",
        "        #c, sigma: (N, g) to (N, g, H, W); mu: (N, g, 3) to (N, g, H, W, 3)\n",
        "        c = self.get_c().unsqueeze(2).unsqueeze(3).repeat(1, 1, H, W)\n",
        "        sigma = self.get_sigma().unsqueeze(2).unsqueeze(3).repeat(1, 1, H, W)\n",
        "        mu = self.mu.unsqueeze(2).unsqueeze(3).repeat(1, 1, H, W, 1)\n",
        "        \n",
        "        return c * torch.exp(-1 * torch.norm(x - mu, dim = -1) ** 2 / (2 * sigma ** 2))\n",
        "    \n",
        "    def project(self, o, n):\n",
        "        \"\"\"\n",
        "        get new gaussian configuration given o and n\n",
        "        o: (3)\n",
        "        n: (H, W, 3)\n",
        "        return: (N, g, H, W) for new_c, new_mu, new_sigma\n",
        "        \"\"\"\n",
        "        \n",
        "        H = n.size()[0]\n",
        "        W = n.size()[1]\n",
        "        \n",
        "        n = F.normalize(n, p = 2, dim = -1)     \n",
        "        new_sigma = self.get_sigma().unsqueeze(2).unsqueeze(3).repeat(1, 1, H, W)\n",
        "        \n",
        "        #mu - o: (N, g, 3) to (N, g, H, W, 3)\n",
        "        mu_o = (self.mu - o).unsqueeze(2).unsqueeze(3).repeat(1, 1, H, W, 1)\n",
        "        new_mu = (mu_o * n).sum(dim = -1)\n",
        "        \n",
        "        #c: (N, g) to (N, g, H, W)\n",
        "        c = self.get_c().unsqueeze(2).unsqueeze(3).repeat(1, 1, H, W)\n",
        "        new_c = c * torch.exp(-1 * (mu_o.norm(dim = -1) ** 2 - new_mu ** 2) / 2 / new_sigma ** 2)\n",
        "        \n",
        "        return new_c, new_mu, new_sigma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hE6TixbU32IB"
      },
      "outputs": [],
      "source": [
        "class Space():\n",
        "    \"\"\"class of the whole space\"\"\"\n",
        "    \n",
        "    def __init__(self, gaussians, step = 1):\n",
        "        '''\n",
        "        gaussains: all the gaussians in the space\n",
        "        step: step length when computing visibility\n",
        "        '''\n",
        "        self.gaus = gaussians\n",
        "        self.step = step\n",
        "        \n",
        "  \n",
        "    def transmittance(self, o, n, s):    \n",
        "        '''\n",
        "        return the transmittance in position s from o along n\n",
        "        o: (3, )\n",
        "        n: (H, W, 3)\n",
        "        s: (N, g, H, W)\n",
        "        return: (N, g, H, W)\n",
        "        '''\n",
        "        \n",
        "        t = torch.zeros_like(s)\n",
        "        n = F.normalize(n, p = 2, dim = -1)\n",
        "        \n",
        "        g = s.size()[1]\n",
        "\n",
        "        #index 2 describes there are g different Gaussians to be considered in each space point, so that we get a density.\n",
        "        #index 1 describes along every direction(defined by pixels and pinhole), there are g different points to consider along the way\n",
        "\n",
        "        #s_new: (N, g, H, W) to (N, g, g, H, W)\n",
        "        s_new = s.unsqueeze(2).repeat(1, 1, g, 1, 1)\n",
        "        \n",
        "        #c, mu, sigma: (N, g, H, W) to (N, g, g, H, W)\n",
        "        c, mu, sigma = self.gaus.project(o, n)\n",
        "        c = c.unsqueeze(1).repeat(1, g, 1, 1, 1)\n",
        "        sigma = sigma.unsqueeze(1).repeat(1, g, 1, 1, 1)\n",
        "        mu = mu.unsqueeze(1).repeat(1, g, 1, 1, 1)\n",
        "        \n",
        "        t = sigma * c / np.sqrt(2. / np.pi) * (torch.erf(-1 * mu / np.sqrt(2.) / sigma) - torch.erf((s_new - mu) / np.sqrt(2.) / sigma))\n",
        "        #t: (N, g, g, H, W) to (N, g, H, W)\n",
        "        t = t.sum(dim = 2)\n",
        "            \n",
        "        return torch.where(s >= 0, torch.exp(t), torch.zeros_like(t))\n",
        "    \n",
        "  \n",
        "    def visibility(self, o, n):\n",
        "        \"\"\"\n",
        "        return the visibility of gaussian g in this space\n",
        "        o: (3, )\n",
        "        n: (H, W, 3)\n",
        "        return: (N, g, H, W)\n",
        "        \"\"\"\n",
        "        \n",
        "        #n = F.normalize(n, p = 2, dim = -1)\n",
        "        _, mu, sigma = self.gaus.project(o, n)\n",
        "        v = torch.zeros_like(mu)\n",
        "        \n",
        "        N = sigma.size()[0]\n",
        "        g = sigma.size()[1]\n",
        "        \n",
        "        #sample range: [-4*sigma : 0]; sample step: sigma * self.step\n",
        "        for i in torch.arange(-4, self.step, self.step):\n",
        "            s = mu + i * sigma\n",
        "            v += self.step * sigma * self.transmittance(o, n, s) * self.gaus.density(o + s.unsqueeze(4) * n)\n",
        "        \n",
        "        return v\n",
        "    \n",
        "    def recv_radiance(self, o, n):\n",
        "        \"\"\"\n",
        "        return received radiance from o in direction n\n",
        "        o: (3, )\n",
        "        n: (H, W, 3)\n",
        "        return: (N, C, H, W)\n",
        "        \"\"\"\n",
        "\n",
        "        n = F.normalize(n, p = 2, dim = -1)\n",
        "        H = n.size()[0]\n",
        "        W = n.size()[1]\n",
        "        C = self.gaus.albedo.size()[2]\n",
        "        \n",
        "        #albedo: (N, g, 3) to (N, g, C, H, W)\n",
        "        albedo = self.gaus.albedo.unsqueeze(3).unsqueeze(4).repeat(1, 1, 1, H, W)\n",
        "        #vis:(N, g, H, W) to (N, g, C, H, W)\n",
        "        vis = self.visibility(o, n).unsqueeze(2).repeat(1, 1, C, 1, 1)\n",
        "        \n",
        "        #return: (N, g, C, H, W) to (N, C, H, W)\n",
        "        return (albedo * vis).sum(dim = 1)\n",
        "    \n",
        "    def draw(self, plane):\n",
        "        \"\"\"project the space on plane\"\"\"\n",
        "        \n",
        "        V = self.recv_radiance(plane.o, plane.get_n())\n",
        "            \n",
        "    \n",
        "        #draw the plane\n",
        "        %matplotlib inline\n",
        "        for i in range(0, V.size()[0]):\n",
        "            sc = plt.imshow(V[i].detach().cpu().transpose(0, 1).transpose(1, 2), alpha = 0.5)\n",
        "            plt.show()\n",
        "        return V    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "4JCjSj9U344H",
        "outputId": "791d0951-df9f-4482-8e5f-51d7a9d8901d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "#updated version of data generation, avoid overlapping by enforcing the distance\n",
        "#between two Gaussians to be more than a threshold\n",
        "#fix the seed\n",
        "torch.manual_seed(101)\n",
        "\n",
        "#training dataset size \n",
        "bs_t = 64\n",
        "\n",
        "#Number of Gaussian \n",
        "ng = 1\n",
        "\n",
        "#manually restrict all Gausssian psf centers to bt within [-10, 10] on x,y axis, 50 on z axis.\n",
        "mu_xy = torch.randint(-10, 10, [bs_t, 1, 2]).to(torch.float)\n",
        "mu_z = 50*torch.ones([bs_t, 1, 1]).to(torch.float)\n",
        "mu = torch.cat((mu_xy, mu_z), dim=-1)\n",
        "\n",
        "for m in range(ng - 1):\n",
        "  mu_m = torch.empty(bs_t, 1, 3)\n",
        "  for n in range(bs_t):\n",
        "    mu_m[n, :, 0:2] = torch.randint(-10, 10, [2], dtype=torch.float)\n",
        "    mu_m[n,:,2] = 50*torch.ones([bs_t, 1, 1])\n",
        "    while True:\n",
        "      flag = True\n",
        "      for i in range(mu.size(1)):\n",
        "        if(torch.dist( mu_m[n,0,0:2], mu[n, i, 0:2] ) < 10.):\n",
        "          flag = False\n",
        "          break\n",
        "      if(flag == True):\n",
        "        break\n",
        "      else:\n",
        "        mu_m[n, :, 0:2] = torch.randint(-10, 10, [2])\n",
        "\n",
        "  mu = torch.cat((mu, mu_m), dim = 1)\n",
        "\n",
        "plane = Plane(torch.Tensor([0., 0., -10.]), torch.Tensor([0., 0., 1.]), torch.Tensor([1., 0., 0.]), torch.Tensor([0., 1., 0.]), 2, 2, 32)\n",
        "\n",
        "c = 5*torch.ones(bs_t, ng)\n",
        "sigma = torch.randint(7,12,[bs_t,ng])\n",
        "albedo = 0.7+0.3*torch.rand([bs_t,ng,3])\n",
        "\n",
        "\n",
        "gau = Gaussian(c,mu,sigma,albedo)\n",
        "space = Space(gau)\n",
        "train_data = space.recv_radiance(plane.o,plane.get_n())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#generate validation dataset \n",
        "\n",
        "bs_v = 32 #Validation dataset size\n",
        "\n",
        "mu_xy_v  = torch.randint(-10, 10, [bs_v, 1, 2]).to(torch.float)\n",
        "mu_z_v = 50*torch.ones([bs_v, 1, 1]).to(torch.float)\n",
        "mu_v = torch.cat((mu_xy_v, mu_z_v), dim=-1)\n",
        "for m in range(ng - 1):\n",
        "  mu_m = torch.empty(bs_v, 1, 3)\n",
        "  for n in range(bs_v):\n",
        "    mu_m[n, :, 0:2] = torch.randint(-10, 10, [2], dtype=torch.float)\n",
        "    mu_m[n,:,2] = 50*torch_ones([bs_v, 1, 1])\n",
        "    while True:\n",
        "      flag = True\n",
        "      for i in range(mu.size(1)):\n",
        "        if(torch.dist( mu_m[n,0,0:2], mu[n, i, 0:2] ) < 10.):\n",
        "          flag = False\n",
        "          break\n",
        "      if(flag == True):\n",
        "        break\n",
        "      else:\n",
        "        mu_m[n, :, 0:2] = torch.randint(-10, 10, [2])\n",
        "\n",
        "  mu_v = torch.cat((mu_v, mu_m), dim = -1)\n",
        "\n",
        "c_v = 5*torch.ones(bs_v, ng)\n",
        "sigma_v = torch.randint(7,12,[bs_v,ng])\n",
        "albedo_v = 0.7+0.3*torch.rand([bs_v,ng,3])\n",
        "gau_v = Gaussian(c_v,mu_v,sigma_v,albedo_v)\n",
        "\n",
        "space_v = Space(gau_v)\n",
        "val_data = space_v.recv_radiance(plane.o,plane.get_n())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(train_data.size())\n",
        "print(val_data.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6mrV4aV85BRV"
      },
      "outputs": [],
      "source": [
        "class GaussianFilter():\n",
        "    \"\"\"\n",
        "    Apply gaussian smoothing on a\n",
        "    1d, 2d or 3d tensor. Filtering is performed seperately for each channel\n",
        "    in the input using a depthwise convolution.\n",
        "    Arguments:\n",
        "        channels (int, sequence): Number of channels of the input tensors. Output will\n",
        "            have this number of channels as well.\n",
        "        kernel_size (int, sequence): Size of the gaussian kernel.\n",
        "        sigma (float, sequence): Standard deviation of the gaussian kernel.\n",
        "        dim (int, optional): The number of dimensions of the data.\n",
        "            Default value is 2 (spatial).\n",
        "    \"\"\"\n",
        "    def __init__(self, channels = 3, kernel_size = 7, sigma = 4, dim=2):\n",
        "        if isinstance(kernel_size, numbers.Number):\n",
        "            kernel_size = [kernel_size] * dim\n",
        "        if isinstance(sigma, numbers.Number):\n",
        "            sigma = [sigma] * dim\n",
        "\n",
        "        # The gaussian kernel is the product of the\n",
        "        # gaussian function of each dimension.\n",
        "        kernel = 1\n",
        "        meshgrids = torch.meshgrid(\n",
        "            [\n",
        "                torch.arange(size, dtype=torch.float32)\n",
        "                for size in kernel_size\n",
        "            ]\n",
        "        )\n",
        "        for size, std, mgrid in zip(kernel_size, sigma, meshgrids):\n",
        "            mean = (size - 1) / 2\n",
        "            kernel *= 1 / (std * math.sqrt(2 * math.pi)) * \\\n",
        "                      torch.exp(-((mgrid - mean) / std) ** 2 / 2)\n",
        "\n",
        "        # Make sure sum of values in gaussian kernel equals 1.\n",
        "        kernel = kernel / torch.sum(kernel)\n",
        "\n",
        "        # Reshape to depthwise convolutional weight\n",
        "        kernel = kernel.view(1, 1, *kernel.size())\n",
        "        kernel = kernel.repeat(channels, *[1] * (kernel.dim() - 1))\n",
        "\n",
        "        self.weight =  kernel\n",
        "        self.groups = channels\n",
        "\n",
        "        if dim == 1:\n",
        "            self.conv = F.conv1d\n",
        "        elif dim == 2:\n",
        "            self.conv = F.conv2d\n",
        "        elif dim == 3:\n",
        "            self.conv = F.conv3d\n",
        "        else:\n",
        "            raise RuntimeError(\n",
        "                'Only 1, 2 and 3 dimensions are supported. Received {}.'.format(dim)\n",
        "            )\n",
        "\n",
        "    def smooth(self, input):\n",
        "        \"\"\"\n",
        "        Apply gaussian filter to input.\n",
        "        Arguments:\n",
        "            input (torch.Tensor): Input to apply gaussian filter on.\n",
        "        Returns:\n",
        "            filtered (torch.Tensor): Filtered output.\n",
        "        \"\"\"\n",
        "        pad_input = F.pad(input, (3,3,3,3), mode = 'replicate')\n",
        "        mediate = self.conv(pad_input, weight=self.weight, groups=self.groups)\n",
        "        pad_mediate = F.pad(mediate, (3,3,3,3), mode = 'replicate')\n",
        "        return self.conv(pad_mediate, weight=self.weight, groups=self.groups)\n",
        "\n",
        "# smoothing = GaussianFilter(3, 7, 2)\n",
        "# input = torch.rand(640, 3, 64, 64)\n",
        "# input = F.pad(input, (3, 3, 3, 3), mode='replicate')\n",
        "# print(input.size())\n",
        "# output = smoothing.smooth(input)\n",
        "# print(output.size())\n",
        "\n",
        "# gf = GaussianFilter(3,7,3)\n",
        "# pad_train_data = F.pad(train_data, (3,3,3,3), mode = 'replicate')\n",
        "# smooth_train_data = gf.smooth(pad_train_data)\n",
        "# print(smooth_train_data.size())\n",
        "\n",
        "# pad_val_data = F.pad(val_data, (3,3,3,3), mode = 'replicate')\n",
        "# smooth_val_data = gf.smooth(pad_val_data)\n",
        "# print(smooth_val_data.size())\n",
        "\n",
        "gf = GaussianFilter()\n",
        "smooth_train_data = gf.smooth(train_data)\n",
        "smooth_val_data = gf.smooth(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "colab_type": "code",
        "id": "9xXur3xuM_23",
        "outputId": "8b7120d7-da0b-4b10-d1f0-7380f71f9aa0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAC6CAYAAAC3HRZZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkEThDZwQQhKFN3BCCEkU3sAJISRR/gW4ImMb2FWEpQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.subplot(121)\n",
        "plt.imshow(train_data[3].cpu().transpose(0,1).transpose(1,2))\n",
        "plt.subplot(122)\n",
        "plt.imshow(smooth_train_data[3].cpu().transpose(0,1).transpose(1,2))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "HjptiEsQOrzr"
      },
      "outputs": [],
      "source": []
    }
  ]
}